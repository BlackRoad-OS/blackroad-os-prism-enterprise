"""Lucidia persona system prompts.

This module centralises the six persona prompts used by the
``lucidia_encompass`` coordinator.

Example
-------
>>> from agents.personas import system_prompt
>>> system_prompt("origin").startswith("You are Lucidia Origin")
True
"""
from __future__ import annotations

from typing import Dict

PERSONAS: Dict[str, str] = {
    "origin": (
        "You are Lucidia Origin, the foundational guardian of BlackRoad's "
        "principles. Evaluate the user's request with diligence. Respond "
        "ONLY as a single JSON object that conforms to schemas/persona_packet.json. "
        "Populate the fields: persona, verdict, balanced_ternary, confidence, "
        "justification, and optional evidence/confidence_notes. Use balanced_ternary "
        "values '+' to affirm, '-' to reject, '0' for neutral. Keep confidence "
        "between 0 and 1."
    ),
    "analyst": (
        "You are Lucidia Analyst, specialising in risk and signal assessment for "
        "BlackRoad. Provide a JSON response only, matching schemas/persona_packet.json "
        "with persona set to 'Analyst'. Offer a cautious verdict, balanced_ternary, "
        "confidence in [0,1], and concise justification." 
    ),
    "archivist": (
        "You are Lucidia Archivist, steward of historical alignment data. Reply with "
        "a JSON object respecting schemas/persona_packet.json. Include persona "
        "='Archivist', a verdict grounded in precedent, balanced_ternary (+/0/-), "
        "confidence within [0,1], justification, and any supporting evidence if helpful."
    ),
    "designer": (
        "You are Lucidia Designer, an integrator focused on user experience and "
        "impact. Respond strictly with JSON conforming to schemas/persona_packet.json, "
        "with persona='Designer'. Report verdict, balanced_ternary (+/0/-), confidence "
        "between 0 and 1, and a succinct justification oriented around human factors."
    ),
    "biologist": (
        "You are Lucidia Biologist, synthesising insights about living systems and "
        "adaptation. Return ONLY JSON aligned to schemas/persona_packet.json with "
        "persona='Biologist'. Supply verdict, balanced_ternary (+/0/-), confidence in "
        "[0,1], justification, and optional evidence."
    ),
    "cartographer": (
        "You are Lucidia Cartographer, mapping operational terrain for Lucidia. "
        "Answer solely with JSON structured per schemas/persona_packet.json. Set persona "
        "='Cartographer', provide verdict, balanced_ternary (+/0/-), confidence within "
        "[0,1], and justification that highlights navigational considerations."
    ),
}


def system_prompt(name: str) -> str:
    """Return the system prompt for the requested persona.
"""Lucidia persona definitions and helpers.

This module provides light-weight personas that can be used with the
:mod:`agents.lucidia_encompass` aggregator.  The personas defined here are
self-contained and do not rely on network access which makes them convenient for
local demos and tests.
"""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import Any, Callable, Dict, Iterable, List, Mapping, MutableMapping, Optional

__all__ = [
    "PersonaPacket",
    "PersonaError",
    "PersonaNetworkError",
    "Persona",
    "load_default_personas",
]


@dataclass
class PersonaPacket:
    """Dataclass describing the response generated by a persona."""

    persona: str
    summary: str
    response: str
    confidence: float
    tokens: List[Dict[str, Any]]
    score: float = 0.0
    metadata: MutableMapping[str, Any] = field(default_factory=dict)
    error: Optional[str] = None

    def as_dict(self) -> Dict[str, Any]:
        """Return a JSON serialisable dictionary representation."""

        return {
            "persona": self.persona,
            "summary": self.summary,
            "response": self.response,
            "confidence": self.confidence,
            "score": self.score,
            "tokens": list(self.tokens),
            "metadata": dict(self.metadata),
            "error": self.error,
        }


class PersonaError(RuntimeError):
    """Generic persona level error."""


class PersonaNetworkError(PersonaError):
    """Raised when a persona fails due to upstream network errors."""


class Persona:
    """Simple persona implementation used by the Lucidia demo stack.

    Parameters
    ----------
    name:
        Persona identifier (case insensitive).

    Returns
    -------
    str
        The system prompt text.

    Raises
    ------
    KeyError
        If the persona name is unknown.
    """

    key = name.lower()
    if key not in PERSONAS:
        raise KeyError(f"Unknown persona '{name}'")
    return PERSONAS[key]
        Human readable identifier.
    voice:
        Tag line describing how the persona communicates.
    focus:
        Iterable of keywords that the persona will emphasise.
    base_confidence:
        Starting confidence score in the range ``[0, 1]``.
    response_builder:
        Optional callable overriding the default deterministic response
        generation.  The callable must accept the user prompt and return a
        mapping with ``response`` and ``summary`` keys (``confidence`` is
        optional).
    """

    def __init__(
        self,
        name: str,
        voice: str,
        focus: Iterable[str],
        *,
        base_confidence: float = 0.6,
        response_builder: Optional[Callable[[str], Mapping[str, Any]]] = None,
    ) -> None:
        self.name = name
        self.voice = voice
        self.focus = list(focus)
        self.base_confidence = max(0.0, min(1.0, float(base_confidence)))
        self._response_builder = response_builder

    def generate_packet(self, prompt: str) -> PersonaPacket:
        """Generate a persona packet for ``prompt``.

        The default implementation is deliberately deterministic so that tests
        and demos produce stable output without requiring LLM calls.
        """

        try:
            if self._response_builder is not None:
                payload = self._response_builder(prompt)
            else:
                payload = self._build_default_payload(prompt)
        except PersonaError:
            raise
        except Exception as exc:  # pragma: no cover - safety net for demos
            raise PersonaError(str(exc)) from exc

        response = str(payload.get("response", "")).strip()
        if not response:
            raise PersonaError(f"Persona '{self.name}' produced an empty response")

        summary = str(payload.get("summary") or self._derive_summary(response))
        confidence = self._clamp_confidence(payload.get("confidence"))
        tokens = self._tokenise_response(response)
        metadata = dict(payload.get("metadata", {}))
        metadata.setdefault("voice", self.voice)
        metadata.setdefault("focus", list(self.focus))

        return PersonaPacket(
            persona=self.name,
            summary=summary,
            response=response,
            confidence=confidence,
            tokens=tokens,
            metadata=metadata,
        )

    def _clamp_confidence(self, confidence: Any) -> float:
        if confidence is None:
            return self.base_confidence
        try:
            value = float(confidence)
        except (TypeError, ValueError) as exc:  # pragma: no cover - defensive
            raise PersonaError("Confidence must be numeric") from exc
        return max(0.0, min(1.0, value))

    def _derive_summary(self, response: str) -> str:
        sentences = response.split(".")
        first_sentence = sentences[0].strip()
        if first_sentence:
            return first_sentence
        return response[:120]

    def _tokenise_response(self, response: str) -> List[Dict[str, Any]]:
        words = response.split()
        if not words:
            return []
        emphasis = set(word.lower().strip(".,!?") for word in self.focus)
        tokens: List[Dict[str, Any]] = []
        base_weight = max(0.1, self.base_confidence / 2)
        for word in words:
            cleaned = word.lower().strip(".,!?:;()").strip()
            weight = base_weight
            if cleaned in emphasis:
                weight = min(1.0, base_weight + 0.35)
            tokens.append({"text": word, "weight": round(weight, 3)})
        return tokens

    def _build_default_payload(self, prompt: str) -> Mapping[str, Any]:
        headline = f"{self.name} perspective"
        focus_clause = " and ".join(self.focus) if self.focus else "the brief"
        response = (
            f"{headline}: Emphasising {focus_clause}, I hear '{prompt}'. "
            f"{self.voice}."
        )
        summary = f"{self.name} focuses on {focus_clause}."
        confidence = self.base_confidence + min(0.15, len(self.focus) * 0.05)
        return {
            "response": response,
            "summary": summary,
            "confidence": confidence,
        }


def load_default_personas() -> List[Persona]:
    """Return a curated list of personas for the demo."""

    return [
        Persona(
            name="Strategist",
            voice="Speaks in pragmatic roadmaps and crisp accountability.",
            focus=("strategy", "outcomes", "milestones"),
            base_confidence=0.72,
        ),
        Persona(
            name="Empath",
            voice="Responds with warmth and relational awareness.",
            focus=("people", "trust", "safety"),
            base_confidence=0.68,
        ),
        Persona(
            name="Technologist",
            voice="Grounds everything in architecture and measurable signals.",
            focus=("systems", "telemetry", "resilience"),
            base_confidence=0.75,
        ),
    ]
