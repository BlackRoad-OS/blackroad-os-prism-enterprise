[tool.poetry]
name = "llm"
version = "0.1.0"
description = "Production-grade LLM inference service with multi-provider support"
authors = ["BlackRoad Team"]
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.11"
fastapi = "^0.115.0"
uvicorn = {extras = ["standard"], version = "^0.31.0"}
pydantic = "^2.9.0"
pydantic-settings = "^2.5.0"
openai = "^1.51.0"
anthropic = "^0.39.0"
httpx = "^0.27.0"
redis = "^5.0.0"
prometheus-client = "^0.21.0"
python-json-logger = "^3.1.0"
tenacity = "^9.0.0"
jinja2 = "^3.1.4"
tiktoken = "^0.8.0"
# Optional heavy dependencies
vllm = {version = "^0.6.0", optional = true}
transformers = {version = "^4.45.0", optional = true}
torch = {version = "^2.4.0", optional = true}

[tool.poetry.extras]
vllm = ["vllm", "torch"]
transformers = ["transformers", "torch"]

[tool.poetry.group.dev.dependencies]
pytest = "^8.3.0"
pytest-asyncio = "^0.24.0"
pytest-cov = "^5.0.0"
httpx = "^0.27.0"
respx = "^0.21.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
addopts = "-v --cov=app --cov-report=term-missing"

[tool.ruff]
line-length = 120
target-version = "py311"

[tool.ruff.lint]
select = ["E", "F", "I", "UP"]
ignore = ["E501"]
